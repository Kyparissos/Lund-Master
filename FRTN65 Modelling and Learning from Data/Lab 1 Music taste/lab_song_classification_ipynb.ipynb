{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x6_Po8c5Yoi"
      },
      "source": [
        "# Import modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGaaR6fA4DM4"
      },
      "source": [
        "# Download data\n",
        "!wget -O training_data.csv http://handsonml.control.lth.se/data/training_data.csv\n",
        "!wget -O songs_to_classify.csv http://handsonml.control.lth.se/data/songs_to_classify.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rQGWXu85GKD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d487f84-98de-428d-b275-e07aae13f63f"
      },
      "source": [
        "# Load data\n",
        "train = pd.read_csv(\"training_data.csv\")\n",
        "test = pd.read_csv(\"songs_to_classify.csv\")\n",
        "\n",
        "\n",
        "qtrain, qtest,= train_test_split( train, test_size=0.4, random_state=42)\n",
        "\n",
        "train.shape, test.shape, qtrain.shape, qtest.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((750, 14), (200, 13), (450, 14), (300, 14))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjIXHj-QbCmK"
      },
      "source": [
        "# Inspect data\n",
        "train.sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.plotting.scatter_matrix(train, figsize=(10, 10));"
      ],
      "metadata": {
        "id": "smqVDc2HVkab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr = train.corr()\n",
        "corr"
      ],
      "metadata": {
        "id": "aszwfvPolSQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "selector  = SelectKBest(chi2, k=10)\n",
        "selector.fit(abs(train.iloc[:,:12]),train.loc[:,'label'].values)\n",
        "cols = selector.get_support(indices=True)\n",
        "features_df_new = abs(train.iloc[:,:12]).iloc[:,cols]\n",
        "features_df_new"
      ],
      "metadata": {
        "id": "UMKP4IAp67Ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slYOHCve8NSi"
      },
      "source": [
        "# select which features to use\n",
        "features = ['danceability','energy','instrumentalness','tempo','acousticness','liveness','speechiness','valence','loudness']\n",
        "X_train = qtrain.loc[:,features].values\n",
        "y_train = qtrain.loc[:,'label'].values\n",
        "X_test = qtest.loc[:,features].values\n",
        "y_test = qtest.loc[:,'label'].values\n",
        "X_test2 = test.loc[:,features].values\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YwzF_SM-FHp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "212458b4-2984-4603-ae8e-056bfd18ba1e"
      },
      "source": [
        "# Normalize data. Can also be done using sklearn methods such as\n",
        "# MinMaxScaler() or StandardScaler()\n",
        "#X_trainn = X_train*1/np.max(np.abs(X_train), axis=0)\n",
        "#X_testn = X_test*1/np.max(np.abs(X_train), axis=0)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "scaler.fit(X_test)\n",
        "#scaler.transform(X_train)\n",
        "#scaler.transform(X_test)\n",
        "X_trainn = scaler.transform(X_train)\n",
        "X_testn = scaler.transform(X_test2)\n",
        "X_qtest = scaler.transform(X_test)\n",
        "X_trainn.shape, y_train.shape, X_qtest.shape, y_test.shape, X_testn.shape\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((450, 9), (450,), (300, 9), (300,), (200, 9))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOQCqMjeaei6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "991cba38-04fd-4ffa-e986-a458c38b5c30"
      },
      "source": [
        "# note: all inputs/features are treated as quantitative/numeric\n",
        "# some of the features are perhaps more sensible to treat as\n",
        "# qualitative/cathegorical. For that sklearn preprocessing methods\n",
        "# such as OneHotEncoder() can be used\n",
        "\n",
        "# define the k-NN model. To set n_neighbors in a systematic way, use cross validation!\n",
        "#knnmodel = KNeighborsClassifier(n_neighbors=5)\n",
        "# feed it with data and train it\n",
        "#knnmodel.fit(X_trainn, y_train)\n",
        "#clf = knnmodel.fit(X_trainn, y_train)\n",
        "#clf = BaggingClassifier(KNeighborsClassifier(),max_samples=0.5, max_features=0.5)\n",
        "#clf = svm.SVC()\n",
        "#model=LogisticRegression()\n",
        "#clf = model.fit(X_trainn, y_train)\n",
        "\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the param grid\n",
        "param_grid = {'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4],\n",
        "        'max_depth': list(range(10, 15)),         \n",
        "        }\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf_Grid = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 10)\n",
        "rf_Grid.fit(X_trainn, y_train)\n",
        "print(\" Results from Grid Search \" )\n",
        "print(\"\\n The best estimator across ALL searched params:\\n\",rf_Grid.best_estimator_)\n",
        "print(\"\\n The best score across ALL searched params:\\n\",rf_Grid.best_score_)\n",
        "print(\"\\n The best parameters across ALL searched params:\\n\",rf_Grid.best_params_)\n",
        "\n",
        "#print (f'Train Accuracy - : {clf.score(X_trainn,y_train):.3f}')\n",
        "#print(\"Best: %f using %s\" % (clf.best_score_,rf_Grid.best_params_))\n",
        "\n",
        "#scores = cross_val_score(clf, X_trainn, y_train, cv=5)\n",
        "#print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
        "\n",
        "# make predictions\n",
        "#predictions = clf.predict(X=X_testn)\n",
        "#print(predictions)\n",
        "#\"\".join([str(int(elem)) for elem in predictions.tolist()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Results from Grid Search \n",
            "\n",
            " The best estimator across ALL searched params:\n",
            " RandomForestClassifier(max_depth=13, min_samples_leaf=2)\n",
            "\n",
            " The best score across ALL searched params:\n",
            " 0.8266666666666665\n",
            "\n",
            " The best parameters across ALL searched params:\n",
            " {'max_depth': 13, 'min_samples_leaf': 2, 'min_samples_split': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GradientBoostingClassifier for boosting\n",
        "#learning_rate = [0.01,0.1]\n",
        "#n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
        "#min_samples_split = [2,3,4]\n",
        "#min_samples_leaf = [1,2]\n",
        "#max_depth = [10,20,30]\n",
        "param_grid = {'learning_rate': [0.01,0.02,0.03],\n",
        "        'n_estimators': [100,500,1000],\n",
        "        'max_depth': [4,6,8],\n",
        "        'subsample': [0.9,0.5,0.2]\n",
        "        }\n",
        "gbc = GradientBoostingClassifier()\n",
        "boost_Grid = GridSearchCV(estimator = gbc, param_grid = param_grid, cv = 5, n_jobs=-1)\n",
        "boost_Grid.fit(X_trainn, y_train)\n",
        "print(\" Results from Grid Search \" )\n",
        "print(\"\\n The best estimator across ALL searched params:\\n\",boost_Grid.best_estimator_)\n",
        "print(\"\\n The best score across ALL searched params:\\n\",boost_Grid.best_score_)\n",
        "print(\"\\n The best parameters across ALL searched params:\\n\",boost_Grid.best_params_)"
      ],
      "metadata": {
        "id": "kCI_yzsoD8go",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2bfefaf-4d45-4a38-8b0d-83a95acf706a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Results from Grid Search \n",
            "\n",
            " The best estimator across ALL searched params:\n",
            " GradientBoostingClassifier(learning_rate=0.01, max_depth=4, n_estimators=1000,\n",
            "                           subsample=0.2)\n",
            "\n",
            " The best score across ALL searched params:\n",
            " 0.8244444444444445\n",
            "\n",
            " The best parameters across ALL searched params:\n",
            " {'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 1000, 'subsample': 0.2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = boost_Grid.best_estimator_\n",
        "y_pred = clf.predict(X_qtest)\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "predictions = clf.predict(X=X_testn)\n",
        "\"\".join([str(int(elem)) for elem in predictions.tolist()])\n",
        "#scores = cross_val_score(clf, X_qtest, y_test, cv=5)\n",
        "#print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "r-VEzC4HBGD4",
        "outputId": "93ed7d48-dfed-486c-f67e-3d534299c222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8433333333333334\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'00010011001101101011001000001111011111010101110110001101100010101111101111110110110101110000001011111010010111111011101001101110101011111111101011001010001111101101111111111001111011111110100111110111'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier()\n",
        "clf.fit(X_trainn, y_train)\n",
        "y_pred = clf.predict(X_qtest)\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "predictions = clf.predict(X=X_testn)\n",
        "\"\".join([str(int(elem)) for elem in predictions.tolist()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "impl4EtUj3jJ",
        "outputId": "ddcaec7d-de1a-4b88-8570-e98e6edb96f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.84\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'00010011001101101011001100000111011111010101110110001101100011100111101011110110110111110000011011111010010111110010101001101110101011111111101011001010001111101101101111111001111011111110100111110111'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = rf_Grid.best_estimator_\n",
        "y_pred = clf.predict(X_qtest)\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "#scores = cross_val_score(clf, X_test, y_test, cv=5)\n",
        "#print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEdSggYQ_t53",
        "outputId": "6fc47c5c-35f6-41c4-828e-4c56d0cfc21e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8333333333333334\n"
          ]
        }
      ]
    }
  ]
}